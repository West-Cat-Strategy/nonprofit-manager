# Production Environment Variables
# CRITICAL: This is a template. Do NOT check actual secrets into version control.
# Use Docker secrets, parameter store, or Vault for production secret management.
# 
# For Docker Compose deployments:
#   1. Copy this file to .env.production
#   2. Replace all placeholder values with REAL, STRONG secrets
#   3. Ensure .env.production is in .gitignore (CRITICAL for security)
#   4. Use `docker-compose --env-file .env.production -f docker-compose.prod.yml up`
#
# For Kubernetes/Cloud deployments:
#   1. Use cloud-native secrets (AWS Secrets Manager, Azure Key Vault, GCP Secret Manager)
#   2. Inject at runtime via environment variables or secret mounts
#   3. Never store secrets in ConfigMaps or container images

# Server
PORT=3000
NODE_ENV=production
LOG_LEVEL=info

# Event Reminder Scheduler
# Enable on exactly one backend worker per environment to avoid duplicate processing.
EVENT_REMINDER_SCHEDULER_ENABLED=false
EVENT_REMINDER_SCHEDULER_INTERVAL_MS=60000
EVENT_REMINDER_SCHEDULER_BATCH_SIZE=25

# Database - Production PostgreSQL instance
# CRITICAL: Use a managed database service (AWS RDS, Azure Database, GCP Cloud SQL) in production
# CRITICAL: Enable SSL/TLS and set sslmode=require
DB_HOST=your-prod-database.example.com
DB_PORT=5432
DB_NAME=nonprofit_manager
DB_USER=nonprofit_app_user_prod
# CRITICAL: Use a strong, randomly generated password (minimum 32 characters)
# Generate with: openssl rand -base64 32
DB_PASSWORD=REPLACE_WITH_STRONG_RANDOM_PASSWORD_MINIMUM_32_CHARS
# SSL/TLS for Database (recommended in production)
# Set to 'false' only for self-signed certificates; prefer 'true' for strict certificate validation
DB_SSL_REJECT_UNAUTHORIZED=true

# Redis Cache - Production Redis instance
# CRITICAL: Use a managed cache service (AWS ElastiCache, Azure Cache, etc.)
# CRITICAL: Enable TLS and require auth
# Use rediss:// protocol instead of redis:// to enable TLS
REDIS_URL=rediss://:REDIS_AUTH_TOKEN@your-prod-redis.example.com:6380
REDIS_ENABLED=true
# TLS for Redis (recommended in production)
# Set to 'false' only for self-signed certificates; prefer 'true' for strict certificate validation
REDIS_TLS_REJECT_UNAUTHORIZED=true

# JWT Authentication
# CRITICAL: Use a strong, randomly generated secret (minimum 32 characters)
# Generate with: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
# MUST NOT contain 'dev', 'test', 'change', or other obvious placeholders
JWT_SECRET=REPLACE_WITH_STRONG_RANDOM_HEX_STRING_MINIMUM_32_CHARS
JWT_EXPIRES_IN=24h
EXPOSE_AUTH_TOKENS_IN_RESPONSE=false

# CSRF Protection
# CRITICAL: Use a strong, randomly generated secret (minimum 32 characters)
# Generate with: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
# MUST NOT contain 'dev', 'test', 'change', or other obvious placeholders
CSRF_SECRET=REPLACE_WITH_STRONG_RANDOM_HEX_STRING_MINIMUM_32_CHARS

# Encryption Key for PII at rest (256-bit)
# CRITICAL: Use a strong, randomly generated key (64 hex characters = 256 bits)
# Generate with: node -e "console.log(require('crypto').randomBytes(32).toString('hex'))"
# CRITICAL: Store separately from other secrets and rotate monthly
ENCRYPTION_KEY=REPLACE_WITH_64_HEX_CHARACTER_256_BIT_KEY

# MFA (TOTP)
TOTP_ISSUER=Nonprofit Manager

# Passkeys (WebAuthn) - Production URLs
# CRITICAL: Set to your production domain
WEBAUTHN_RP_NAME=Nonprofit Manager
WEBAUTHN_ORIGIN=https://your-production-domain.com
WEBAUTHN_RP_ID=your-production-domain.com

# CORS - Production frontend origin
# CRITICAL: Restrict to your production frontend domain only
CORS_ORIGIN=https://your-production-domain.com

# Stripe Payment Processing
# Get REAL keys from https://dashboard.stripe.com/apikeys (production environment)
# CRITICAL: Use LIVE keys (sk_live_*, pk_live_*), NOT test keys
STRIPE_SECRET_KEY=sk_live_REPLACE_WITH_ACTUAL_STRIPE_LIVE_SECRET
STRIPE_PUBLISHABLE_KEY=pk_live_REPLACE_WITH_ACTUAL_STRIPE_LIVE_PUBLISHABLE
# Get webhook secret from https://dashboard.stripe.com/webhooks
# CRITICAL: Must match the secret for your production webhook endpoint
STRIPE_WEBHOOK_SECRET=whsec_REPLACE_WITH_ACTUAL_STRIPE_WEBHOOK_SECRET

# Health Check Authentication
# CRITICAL: Use a strong, random token to protect health check endpoint
HEALTH_CHECK_KEY=REPLACE_WITH_STRONG_RANDOM_TOKEN

# Metrics Authentication
# CRITICAL: Use a strong, random token to protect metrics endpoint
METRICS_AUTH_KEY=REPLACE_WITH_STRONG_RANDOM_TOKEN

# Mailchimp Email Marketing
# Get API key from https://admin.mailchimp.com/account/api/ (production account)
# Server prefix is the datacenter (e.g., us1, us2, etc.) from your API key
MAILCHIMP_API_KEY=REPLACE_WITH_ACTUAL_MAILCHIMP_API_KEY
MAILCHIMP_SERVER_PREFIX=us1

# Plausible Analytics
# Get API key from https://plausible.io/settings/api (if used)
PLAUSIBLE_API_KEY=REPLACE_WITH_ACTUAL_PLAUSIBLE_API_KEY
PLAUSIBLE_API_HOST=https://plausible.io
PLAUSIBLE_DOMAIN=your-production-domain.com

# Security Configuration
# Set to true to enforce secure config validation and exit if secrets are weak (RECOMMENDED)
ENFORCE_SECURE_CONFIG=true

# Organization Context
# Set to true to require organization context in all API requests (RECOMMENDED)
ORG_CONTEXT_REQUIRE=true
ORG_CONTEXT_VALIDATE=true

# Error Tracking (Sentry)
# Optional but recommended for production monitoring
# Get DSN from: https://sentry.io/projects/
SENTRY_DSN=https://your_sentry_project_key@sentry.io/your_project_id
RELEASE_VERSION=1.0.0

# Content Security Policy (CSP) Report URI
# Optional: reports CSP violations to your endpoint
# Example: https://your-csp-endpoint.example.com/csp-report
CSP_REPORT_URI=

# API Origin (for CORS and CSP)
# Should match backend CORS_ORIGIN
API_ORIGIN=https://api.your-production-domain.com
# Log Aggregation (HIGHLY RECOMMENDED for production)
# Centralized logging is critical for monitoring, debugging, and compliance
# Choose one of: ELK Stack, Loki, Datadog, CloudWatch, or Splunk
# See docs/LOG_AGGREGATION_SETUP.md for detailed configuration
LOG_AGGREGATION_ENABLED=true

# Log Aggregation - ELK Stack (self-hosted Elasticsearch/Logstash)
# Example configuration:
# LOG_AGGREGATION_HOST=logstash.internal.example.com
# LOG_AGGREGATION_PORT=8080
# LOG_AGGREGATION_PATH=/logs
# LOG_AGGREGATION_PROTOCOL=http

# Log Aggregation - Loki (Grafana Loki)
# Example configuration:
# LOG_AGGREGATION_HOST=loki.internal.example.com
# LOG_AGGREGATION_PORT=3100
# LOG_AGGREGATION_PATH=/loki/api/v1/push
# LOG_AGGREGATION_PROTOCOL=http

# Log Aggregation - Datadog
# Get API key from: https://app.datadoghq.com/account/settings#api/overview
# LOG_AGGREGATION_HOST=http-intake.logs.datadoghq.com
# LOG_AGGREGATION_PORT=443
# LOG_AGGREGATION_PATH=/v1/input/YOUR_DATADOG_API_KEY
# LOG_AGGREGATION_PROTOCOL=https

# Log Aggregation - Generic HTTP endpoint
# Replace with your actual log aggregation service details
LOG_AGGREGATION_HOST=your-log-aggregation-host.example.com
LOG_AGGREGATION_PORT=8080
LOG_AGGREGATION_PATH=/logs
LOG_AGGREGATION_PROTOCOL=https
LOG_AGGREGATION_API_KEY=REPLACE_WITH_LOG_SERVICE_API_KEY_IF_REQUIRED
