# Logstash Pipeline Configuration
# Receives JSON logs from the Node.js backend via HTTP and routes to Elasticsearch
#
# Input: HTTP POST /logs with JSON body
# Filter: Parse JSON, normalize fields, add metadata
# Output: Send to Elasticsearch with date-based indices
#

input {
  http {
    port => 8080
    codec => "json"
    # Optional: Add basic auth
    # user => "logstash"
    # password => "secure_password_here"
  }
}

filter {
  # Parse timestamp if it's a string
  if [timestamp] {
    date {
      match => ["timestamp", "ISO8601"]
      target => "@timestamp"
      timezone => "UTC"
    }
  }

  # Extract request ID for correlation
  if [requestId] {
    mutate {
      add_field => {"correlationId" => "%{requestId}"}
    }
  }

  # Parse nested error objects
  if [error] and [error][message] {
    mutate {
      add_field => {"error_message" => "%{[error][message]}"}
      add_field => {"error_type" => "%{[error][name]}"}
    }
  }

  # Normalize log levels
  mutate {
    lowercase => ["level"]
  }

  # Add service metadata
  if ![service] {
    mutate {
      add_field => {"service" => "nonprofit-manager-api"}
    }
  }

  # Add environment if not present
  if ![environment] {
    mutate {
      add_field => {"environment" => "%{ENVIRONMENT:production}"}
    }
  }

  # Extract status code for easier filtering
  if [statusCode] {
    mutate {
      add_field => {
        "status_code" => "%{statusCode}"
        "status_category" => "error"
      }
    }
    if [statusCode] >= 200 and [statusCode] < 300 {
      mutate {
        replace => {"status_category" => "success"}
      }
    } else if [statusCode] >= 300 and [statusCode] < 400 {
      mutate {
        replace => {"status_category" => "redirect"}
      }
    } else if [statusCode] >= 400 and [statusCode] < 500 {
      mutate {
        replace => {"status_category" => "client_error"}
      }
    } else if [statusCode] >= 500 {
      mutate {
        replace => {"status_category" => "server_error"}
      }
    }
  }

  # Parse duration strings (e.g., "145ms" -> 145)
  if [duration] =~ /ms$/ {
    mutate {
      gsub => ["duration", "ms", ""]
    }
    mutate {
      convert => {"duration" => "integer"}
    }
  }

  # Remove noisy fields if needed
  mutate {
    remove_field => ["host", "port"]
  }
}

output {
  # Send to Elasticsearch with date-based indices
  elasticsearch {
    hosts => ["elasticsearch:9200"]
    index => "logs-%{service}-%{+YYYY.MM.dd}"
    codec => "json"
  }

  # Optional: Also output to stdout for debugging
  # stdout {
  #   codec => rubydebug
  # }

  # Optional: Filter and send specific log types to separate indices
  if [level] == "error" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "logs-%{service}-errors-%{+YYYY.MM.dd}"
      codec => "json"
    }
  }

  if [eventType] == "security" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "logs-%{service}-security-%{+YYYY.MM.dd}"
      codec => "json"
    }
  }

  if [eventType] == "audit" {
    elasticsearch {
      hosts => ["elasticsearch:9200"]
      index => "logs-%{service}-audit-%{+YYYY.MM.dd}"
      codec => "json"
    }
  }
}
